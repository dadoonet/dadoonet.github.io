{"data":[{"type":"presentations","id":"pr_N1EmNk","attributes":{"title":"Centralized Logging Patterns","slug":"centralized-logging-patterns","blurb":{"html":"<p>Monitoring an entire application is not a simple task, but with the right tools it is not a hard task either. However, events like Black Friday can push your application to the limit, and even cause crashes. As the system is stressed, it generates a lot more logs, which may crash the monitoring system as well. In this talk I will walk through the best practices when using the Elastic Stack to centralize and monitor your logs. I will also share some tricks to help you with the huge increase of traffic typical in Black Fridays.<\/p>\n<p>Topics include:<\/p>\n<ul>\n<li>monitoring architectures<\/li>\n<li>optimal bulk size<\/li>\n<li>distributing the load<\/li>\n<li>index and shard size<\/li>\n<li>optimizing disk IO<\/li>\n<\/ul>\n<p>Takeaway: best practices when building a monitoring system with the Elastic Stack, advanced tuning to optimize and increase event ingestion performance.<\/p>\n"},"slidedeck":{"data":[{"id":"sd_1719","type":"images","slides":[{"id":"sl_3aRn8W","type":"image","title":null,"desc":{"html":"<p>Centralized Logging Patterns Les vendredi noirs ? M\u00eame pas peur !\nDavid Pilato Developer | Evangelist, @dadoonet<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck1719\/large-0.jpg","html":null},{"id":"sl_fuAb0v","type":"image","title":null,"desc":{"html":"<p>Data Platform Architectures<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck1719\/large-1.jpg","html":null},{"id":"sl_IDtOtK","type":"image","title":null,"desc":{"html":"<p>The Elastic Journey of Data Beats\nElasticsearch Logstash\nLog Files\nWire Data\nMaster Nodes (3)\nKibana\nIngest Nodes (X) Metrics your{beat}\nKafka\nNodes (X) Redis\nMessaging Queue\nData Store\nWeb APIs\nSocial\nSensors\nData Nodes Hot (X) Data Notes Warm (X)\nQueues\n!9\nInstances (X)\n@dadoonet\nStorage\nMetrics Notification\nsli.do\/elastic<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck1719\/large-2.jpg","html":null},{"id":"sl_uXcClj","type":"image","title":null,"desc":{"html":"<p>App Search\nSite Search\nEnterprise Search\nLogging\nAPM\nBusiness Analytics\nSecurity Analytics\nMetrics\nElastic Stack\nFuture\nSolutions\nKibana\nVisualize &amp; Manage\nElasticsearch\nStore, Search, &amp; Analyze\nBeats\nSaaS\nElastic Cloud\nLogstash\nIngest\nSelf Managed\nStandalone\nElastic Cloud Enterprise\nDeployment<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck1719\/large-3.png","html":null},{"id":"sl_WrL0e8","type":"image","title":null,"desc":{"html":"<p>Elasticsearch Cluster Sizing<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck1719\/large-4.png","html":null},{"id":"sl_9B3oWX","type":"image","title":null,"desc":{"html":"<p>Terminology Cluster my_cluster Server 1 Node A d1 d3\nd6 d2\nd4 d9 d12\nd11 d7 d8\nd5\nd3 d1\nd10\nd4\nIndex twitter\nd6 d2 d5\nIndex logs\n!12\n@dadoonet\nsli.do\/elastic<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck1719\/large-5.jpg","html":null},{"id":"sl_lUmcOw","type":"image","title":null,"desc":{"html":"<p>Partition Cluster my_cluster Server 1 d1\n4\nd3\n3\nNode A\nd2 d4 d9 d12\n2\nShards\nd6 d11 d7 d8\nd5 d10\n0\n1\n1\nd3\nd1 d4\nIndex twitter\nd6 d2 d5\n0\nIndex logs\n!13\n@dadoonet\nsli.do\/elastic<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck1719\/large-6.jpg","html":null},{"id":"sl_NoVQHL","type":"image","title":null,"desc":{"html":"<p>Distribution Cluster my_cluster Server 1\nServer 2 twitter shard P4\nd1 d6\nNode B\nNode A\ntwitter shard P1\nd2 d5\nd3\nd10\nd11\ntwitter shard P0\nd7 d8\nd4 d9\ntwitter shard P3 d12\ntwitter shard P2\n!14\nd3 d1\n@dadoonet\nd6\nlogs shard P0\nd2\nd4\nd5\nlogs shard P1\nsli.do\/elastic<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck1719\/large-7.jpg","html":null},{"id":"sl_08EE9k","type":"image","title":null,"desc":{"html":"<p>Replication \u2022 Primaries \u2022 Replicas Cluster my_cluster Server 1\nServer 2 twitter shard P4\nNode B\nd1 d6 d2\nd11 d7\nd3\ntwitter shard R3 d9\nd12\ntwitter shard P2\n!15\ntwitter shard P1\nd5\nd2\nd2 d11\nd5 d1\n@dadoonet\nd6\nd8\nd9\nlogs shard R0\ntwitter shard P3\nlogs shard P0\ntwitter shard R2\ntwitter shard P0\nd7\nd6\nd2\nd4\nd5 d10\nd3\nd1\ntwitter shard R1\nd12 d3\nNode A\nd4\ntwitter shard R0 logs shard R1 d4\nd6\nd3\nd10\nd8\nd4\ntwitter shard R4\nd1\nd5\nlogs shard P1\nsli.do\/elastic<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck1719\/large-8.jpg","html":null},{"id":"sl_cRx229","type":"image","title":null,"desc":{"html":"<p>Replication\nServer 3 twitter shard R4\nd1 d6\nServer 2\nNode C\ntwitter shard P4\ntwitter shard P1\nd2\nd10\ntwitter shard R3 d9\ntwitter shard P2\n!16\nd6\nNode A\nd2\nd8\nd4\nd2\nd3 d1\nlogs shard P1\n@dadoonet\nlogs shard R0\ntwitter shard P3\ntwitter shard R1\nd12\nd5 d5\nd8\nd9\nd2 d6\nlogs shard P0\ntwitter shard R2\nsli.do\/elastic\ntwitter shard P0\nd7\nd4\ntwitter shard R0 logs shard R1 d4\nd11\nd3\nd7\nd3\nd4\nNode B\nd1\nd11\nd5\nd12\n\u2022 Primaries \u2022 Replicas Cluster my_cluster Server 1\nd5 d10\nd1\nd3\nd6<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck1719\/large-9.jpg","html":null},{"id":"sl_ElfpuY","type":"image","title":null,"desc":{"html":"<p>Scaling Big Data\n...\n...\n\u2022 In Elasticsearch, shards are the working unit \u2022 More data -&gt; More shards\nBut how many shards? !21\n@dadoonet\nsli.do\/elastic<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck1719\/large-10.png","html":null},{"id":"sl_r5Odmx","type":"image","title":null,"desc":{"html":"<p>How much data?\n\u2022 ~1000 events per second \u2022 60s * 60m * 24h * 1000 events =&gt; ~87M events per day \u2022 1kb per event =&gt; ~82GB per day \u2022 3 months =&gt; ~7TB\n!22\n@dadoonet\nsli.do\/elastic<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck1719\/large-11.jpg","html":null},{"id":"sl_TP7RfM","type":"image","title":null,"desc":{"html":"<p>Shard Size \u2022 It depends on many different factors \u2012 document size, mapping, use case, kinds of queries being executed, desired response time, peak indexing rate, budget, ... \u2022 After the shard sizing*, each shard should handle 45GB \u2022 Up to 10 shards per machine<\/p>\n<ul>\n<li>https:\/\/www.elastic.co\/elasticon\/conf\/2016\/sf\/quantitative-cluster-sizing !23\n@dadoonet\nsli.do\/elastic<\/li>\n<\/ul>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck1719\/large-12.jpg","html":null},{"id":"sl_5iqFXl","type":"image","title":null,"desc":{"html":"<p>How many shards?\n\u2022 Data size: ~7TB\n\u2022\nShards per machine: 10*\n\u2022 Shard Size: ~45GB*\n\u2022\nTotal Servers: 16\n\u2022 Total Shards: ~160 3 months of logs Cluster my_cluster\n... * https:\/\/www.elastic.co\/elasticon\/conf\/2016\/sf\/quantitative-cluster-sizing !24\n@dadoonet\nsli.do\/elastic<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck1719\/large-13.png","html":null},{"id":"sl_i2Z3QA","type":"image","title":null,"desc":{"html":"<p>But...\n\u2022 How many indices? \u2022 What do you do if the daily data grows? \u2022 What do you do if you want to delete old data?\n!25\n@dadoonet\nsli.do\/elastic<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck1719\/large-14.jpg","html":null},{"id":"sl_KMHrIZ","type":"image","title":null,"desc":{"html":"<p>Time-Based Data\n\u2022 Logs, social media streams, time-based events \u2022 Timestamp + Data \u2022 Do not change \u2022 Typically search for recent events \u2022 Older documents become less important \u2022 Hard to predict the data size\n!26\n@dadoonet\nsli.do\/elastic<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck1719\/large-15.png","html":null},{"id":"sl_wg0fAy","type":"image","title":null,"desc":{"html":"<p>Time-Based Data\n\u2022 Time-based Indices is the best option \u2012 create a new index each day, week, month, year, ... \u2012 search the indices you need in the same request\n!27\n@dadoonet\nsli.do\/elastic<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck1719\/large-16.png","html":null},{"id":"sl_YzjT3N","type":"image","title":null,"desc":{"html":"<p>Daily Indices Cluster my_cluster d3 d1 d4\nd6 d2 d5\nlogs-2018-04-10\n!28\n@dadoonet<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck1719\/large-17.jpg","html":null},{"id":"sl_BJSGvm","type":"image","title":null,"desc":{"html":"<p>Daily Indices Cluster my_cluster d3 d1 d4\nd6 d2 d5\nlogs-2018-04-10 d3 d1 d4\nd6 d2 d5\nlogs-2018-04-11\n!29\n@dadoonet<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck1719\/large-18.jpg","html":null},{"id":"sl_ndB4oB","type":"image","title":null,"desc":{"html":"<p>Daily Indices Cluster my_cluster d3 d1 d4\nd6 d2 d5\nlogs-2018-04-10 d3 d1 d4\nd6 d2 d5\nlogs-2018-04-11 d3 d1 d4\nd6 d2 d5\nlogs-2018-04-12 !30\n@dadoonet<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck1719\/large-19.jpg","html":null},{"id":"sl_Pwtsga","type":"image","title":null,"desc":{"html":"<p>Templates\n\u2022 Every new created index starting with 'logs-' will have \u2012 2 shards \u2012 1 replica (for each primary shard) \u2012 60 seconds refresh interval PUT _template\/logs { &quot;template&quot;: &quot;logs-*&quot;, &quot;settings&quot;: { &quot;number_of_shards&quot;: 2, &quot;number_of_replicas&quot;: 1, &quot;refresh_interval&quot;: &quot;60s&quot; } }\nMore on that later !31\n@dadoonet<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck1719\/large-20.png","html":null},{"id":"sl_2GcgYz","type":"image","title":null,"desc":{"html":"<p>Alias Cluster my_cluster d3 d1 d4\nd2 d5\nlogs-write\nlogs-2018-04-10\nlogs-read Application\nusers\n!32\nd6\n@dadoonet<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck1719\/large-21.jpg","html":null},{"id":"sl_eaLURO","type":"image","title":null,"desc":{"html":"<p>Alias Cluster my_cluster d3 d1 d4\nd6 d2 d5\nlogs-write\nlogs-2018-04-10 d3 d1\nlogs-read Application\nd4\nd6 d2 d5\nlogs-2018-04-11\nusers\n!33\n@dadoonet<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck1719\/large-22.jpg","html":null},{"id":"sl_Gu4IJn","type":"image","title":null,"desc":{"html":"<p>Alias Cluster my_cluster d3 d1 d4\nd6 d2 d5\nlogs-write\nlogs-2018-04-10 d3 d1\nlogs-read Application\nd4\nd6 d2 d5\nlogs-2018-04-11 d3 d1\nusers\nd4\nd6 d2 d5\nlogs-2018-04-12 !34\n@dadoonet<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck1719\/large-23.jpg","html":null},{"id":"sl_tDn6CC","type":"image","title":null,"desc":{"html":"<p>Detour: Rollover API\nhttps:\/\/www.elastic.co\/guide\/en\/elasticsearch\/reference\/6.3\/indices-rollover-index.html<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck1719\/large-24.jpg","html":null},{"id":"sl_VXVu4b","type":"image","title":null,"desc":{"html":"<p>Do not Overshard don't keep default values!\nCluster my_cluster d3\nd6\nd1\n\u2022 3 different logs\nd2\nd4\nd5\n\u2022 1 index per day each\naccess-...\n\u2022 1GB each\nd5\n\u2022 5 shards (default): so 200mb \/ shard vs 45gb\nd1 d7\nd6 d9 d5\n\u2022 6 months retention\napplication-...\n\u2022 ~900 shards for ~180GB\nd59\n\u2022 we needed ~4 shards!\nd0 d4\nd10 d3 d5\nmysql-... !36\n@dadoonet\nsli.do\/elastic<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck1719\/large-25.jpg","html":null},{"id":"sl_7rEhx0","type":"image","title":null,"desc":{"html":"<p>Scaling Big Data 1M users\n...\n...\nBut what happens if we have 2M users?\n!38\n@dadoonet\nsli.do\/elastic<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck1719\/large-26.png","html":null},{"id":"sl_kAxVpP","type":"image","title":null,"desc":{"html":"<p>Scaling Big Data\n!39\n1M users\n...\n...\n1M users\n...\n...\n@dadoonet\nsli.do\/elastic<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck1719\/large-27.png","html":null},{"id":"sl_MUgJho","type":"image","title":null,"desc":{"html":"<p>Scaling Big Data\n!40\n1M users\n...\n...\n1M users\n...\n...\n1M users\n...\n...\n@dadoonet\nsli.do\/elastic<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck1719\/large-28.png","html":null},{"id":"sl_yoP7aD","type":"image","title":null,"desc":{"html":"<p>Scaling Big Data\nU s e r s\n!41\n...\n...\n...\n...\n...\n...\n@dadoonet\nsli.do\/elastic<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck1719\/large-29.png","html":null},{"id":"sl_b87vSc","type":"image","title":null,"desc":{"html":"<p>Shards are the working unit\n\u2022 Primaries \u2012 More data -&gt; More shards \u2012 write throughput (More writes -&gt; More primary shards) \u2022 Replicas \u2012 high availability (1 replica is the default) \u2012 read throughput (More reads -&gt; More replicas)\n!42\n@dadoonet\nsli.do\/elastic<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck1719\/large-30.png","html":null},{"id":"sl_DRqjL1","type":"image","title":null,"desc":{"html":"<p>Detour: Shrink API\nhttps:\/\/www.elastic.co\/guide\/en\/elasticsearch\/reference\/6.3\/indices-shrink-index.html<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck1719\/large-31.jpg","html":null},{"id":"sl_plZXDQ","type":"image","title":null,"desc":{"html":"<p>Detour: Split API\nhttps:\/\/www.elastic.co\/guide\/en\/elasticsearch\/reference\/6.3\/indices-split-index.html<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck1719\/large-32.jpg","html":null},{"id":"sl_S5IL5p","type":"image","title":null,"desc":{"html":"<p>Optimal Bulk Size<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck1719\/large-33.jpg","html":null},{"id":"sl_4P18yE","type":"image","title":null,"desc":{"html":"<p>What is Bulk? 1000 index requests with 1 document __________ __________ __________ __________ __________ __________ __________ __________ __________ __________ __________ __________ __________ __________ __________ __________ __________ __________ __________ __________ __________ __________ __________ __________ __________ __________ __________ __________ __________ __________ __________ __________ __________ __________ __________ __________ __________ __________ __________ __________ _____\nMaster Nodes (3) Ingest Nodes (X)\nBeats Logstash Application\nData Nodes Hot (X)\n1000 log events\n1 bulk request with 1000 documents\n!46\nElasticsearch\n@dadoonet\nsli.do\/elastic\nData Notes Warm (X) X-Pack<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck1719\/large-34.jpg","html":null},{"id":"sl_gijwqd","type":"image","title":null,"desc":{"html":"<p>What is the optimal bulk size? Elasticsearch<\/p>\n<hr \/>\n<p>Beats Logstash Application\n1000 log events\n4 * 250? 2 * 500? 1 * 1000?\nMaster Nodes (3) Ingest Nodes (X) Data Nodes Hot (X) Data Notes Warm (X) X-Pack\n!47\n@dadoonet\nsli.do\/elastic<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck1719\/large-35.jpg","html":null},{"id":"sl_J2Skj2","type":"image","title":null,"desc":{"html":"<p>It depends...\n\u2022 on your application (language, libraries, ...) \u2022 document size (100b, 1kb, 100kb, 1mb, ...) \u2022 number of nodes \u2022 node size \u2022 number of shards \u2022 shards distribution\n!48\n@dadoonet\nsli.do\/elastic<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck1719\/large-36.png","html":null},{"id":"sl_vMBYbR","type":"image","title":null,"desc":{"html":"<p>Test it ;) Elasticsearch<\/p>\n<hr \/>\n<p>1000000 log events\n4000 * Beats Logstash Application\n2000 *\n250-&gt; 160s\nMaster Nodes (3)\n500-&gt; 164s\nIngest Nodes (X)\n1000 * 1000-&gt; 155s\nData Nodes Hot (X) Data Notes Warm (X) X-Pack\n!49\n@dadoonet\nsli.do\/elastic<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck1719\/large-37.jpg","html":null},{"id":"sl_XfuMTq","type":"image","title":null,"desc":{"html":"<p>Test it ;) input { stdin{} } filter {} output { elasticsearch { hosts =&gt; [&quot;10.12.145.189&quot;] flush_size =&gt; &quot;${SIZE}&quot; } }\nIn Beats set &quot;bulk_max_size&quot; in the output.elasticsearch\nDATE=<code>date +%Y.%m.%d<\/code> LOG=logs\/logs.txt exec_test () { curl -s -XDELETE &quot;http:\/\/USER:PASS@HOST:9200\/logstash-$DATE&quot; sleep 10 export SIZE=$1 time cat $LOG | .\/bin\/logstash -f logstash.conf } for SIZE in 100 500 1000 3000 5000 10000; do for i in {1..20}; do exec_test $SIZE done; done; !50\n@dadoonet\nsli.do\/elastic<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck1719\/large-38.png","html":null},{"id":"sl_9zdAMF","type":"image","title":null,"desc":{"html":"<p>Test it ;)\n\u2022 2 node cluster (m3.large) \u2012 2 vCPU, 7.5GB Memory, 1x32GB SSD \u2022 1 index server (m3.large) \u2012 logstash \u2012 kibana\n!51<\/p>\n<h1>docs<\/h1>\n<p>100\n500\n1000\n3000\n5000\n10000\ntime(s)\n191.7\n161.9\n163.5\n160.7\n160.7\n161.5\n@dadoonet<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck1719\/large-39.png","html":null},{"id":"sl_mJLyEe","type":"image","title":null,"desc":{"html":"<p>Distribute the Load<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck1719\/large-40.jpg","html":null},{"id":"sl_Od4m73","type":"image","title":null,"desc":{"html":"<p>Avoid Bottlenecks Elasticsearch\nsingle node _________ _________ _________ _________ _________ _________ _________ _________ _________ _________ _________ _________ _________ _________ _________ _________ _________ _________ _________ _________ _________ _________ _________ _________ _________ _________ _________ _________ _________ _________ _________ _________ _________ _________ _________\n1000000 log events\nNode 1 Beats Logstash Application\nround robin\noutput { elasticsearch { hosts =&gt; [&quot;node1&quot;,&quot;node2&quot;] } }\n!53\n@dadoonet\nNode 2\nX-Pack<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck1719\/large-41.jpg","html":null},{"id":"sl_0wnZzS","type":"image","title":null,"desc":{"html":"<p>Load Balancer Elasticsearch<\/p>\n<hr \/>\n<p>Node 1 Beats Logstash\nLB\nApplication\nNode 2\n1000000 log events\nX-Pack\n!54\n@dadoonet<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck1719\/large-42.jpg","html":null},{"id":"sl_dGWNrr","type":"image","title":null,"desc":{"html":"<p>Coordinating-only Node Elasticsearch<\/p>\n<hr \/>\n<p>Node 1 Beats\nNode 3 co-node\nLogstash Application\nNode 2\n1000000 log events\nX-Pack\n!55\n@dadoonet<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck1719\/large-43.jpg","html":null},{"id":"sl_FaFBkG","type":"image","title":null,"desc":{"html":"<p>Test it ;) \u2022 2 node cluster (m3.large) \u2012 2 vCPU, 7.5GB Memory, 1x32GB SSD \u2022 1 index server (m3.large) \u2012 logstash (round robin configured) \u2012\nhosts =&gt; [&quot;10.12.145.189&quot;, &quot;10.121.140.167&quot;]\n\u2012 kibana\n!56\n#docs time(s)\n1000\n5000\n10000\nNO Round Robin\n163.5\n160.7\n161.5\nRound Robin\n161.3\n158.2\n159.4\n@dadoonet<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck1719\/large-44.png","html":null},{"id":"sl_rtxzcf","type":"image","title":null,"desc":{"html":"<p>Optimizing Disk IO<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck1719\/large-45.jpg","html":null},{"id":"sl_UDgnV4","type":"image","title":null,"desc":{"html":"<p>Durability time buffer index a doc\nbuffer index a doc\nbuffer index a doc\nbuffer\n!58\n@dadoonet\nlucene flush\nsegment<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck1719\/large-46.png","html":null},{"id":"sl_6XPbNT","type":"image","title":null,"desc":{"html":"<p>refresh_interval\n\u2022 Dynamic per-index setting PUT logstash-2017.05.16\/_settings { &quot;refresh_interval&quot;: &quot;60s&quot; }\n\u2022 Increase to get better write throughput to an index \u2022 New documents will take more time to be available for Search.\n!59\n#docs time(s)\n1000\n5000\n10000\n1s refresh 60s refresh\n161.3 156.7\n158.2 152.1\n159.4 152.6\n@dadoonet<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck1719\/large-47.png","html":null},{"id":"sl_ir8PFs","type":"image","title":null,"desc":{"html":"<p>Durability time\nbuffer index a doc\ndoc op\ntrans_log buffer\nlucene flush\nsegment\ntrans_log buffer elasticsearch flush\nlucene commit\ntrans_log\n!60\n@dadoonet\nsegment segment<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck1719\/large-48.png","html":null},{"id":"sl_LArD8H","type":"image","title":null,"desc":{"html":"<p>Translog fsync every 5s (1.7) buffer\nPrimary\nindex a doc\ndoc op\ntrans_log buffer\nReplica\nindex a doc\ndoc op\ntrans_log\nredundancy doesn\u2019t help if all nodes lose power !61\n@dadoonet<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck1719\/large-49.jpg","html":null},{"id":"sl_xUa10g","type":"image","title":null,"desc":{"html":"<p>Async Transaction Log \u2022 index.translog.durability \u2012 request (default) \u2012 async \u2022 index.translog.sync_interval (only if async is set) \u2022 Dynamic per-index settings \u2022 Be careful, you are relaxing the safety guarantees\n!62\n#docs time(s)\n1000\n5000\n10000\nRequest fsync\n161.3\n158.2\n159.4\n5s sync\n152.4\n149.1\n150.3\n@dadoonet<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck1719\/large-50.png","html":null},{"id":"sl_ZoIot5","type":"image","title":null,"desc":{"html":"<p>Final Remarks<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck1719\/large-51.jpg","html":null},{"id":"sl_C81clU","type":"image","title":null,"desc":{"html":"<p>App Search\nSite Search\nEnterprise Search\nLogging\nAPM\nBusiness Analytics\nSecurity Analytics\nMetrics\nElastic Stack\nFuture\nSolutions\nKibana\nVisualize &amp; Manage\nElasticsearch\nStore, Search, &amp; Analyze\nBeats\nSaaS\nElastic Cloud\nLogstash\nIngest\nSelf Managed\nStandalone\nElastic Cloud Enterprise\nDeployment<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck1719\/large-52.png","html":null},{"id":"sl_oRkQdt","type":"image","title":null,"desc":{"html":"<p>Final Remarks \u2022 Primaries \u2012 More data -&gt; More shards \u2012 Do not overshard! \u2022 Replicas \u2012 high availability (1 replica is the default) \u2012 read throughput (More reads -&gt; More replicas) Big Data\nU s e r s\n!65\n@dadoonet\n...\n...\n...\n...\n...\n...\nsli.do\/elastic<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck1719\/large-53.png","html":null},{"id":"sl_QlTEWI","type":"image","title":null,"desc":{"html":"<p>Final Remarks \u2022 Bulk and Test \u2022 Distribute the Load \u2022 Refresh Interval \u2022 Async Trans Log (careful)\n!66\n#docs per bulk\n1000\n5000\n10000\nDefault\n163.5\n160.7\n161.5\nRR+60s+Async5s\n152.4\n149.1\n150.3\n@dadoonet<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck1719\/large-54.png","html":null},{"id":"sl_35C2Oh","type":"image","title":null,"desc":{"html":"<p>Centralized Logging Patterns Les vendredi noirs ? M\u00eame pas peur !\nDavid Pilato Developer | Evangelist, @dadoonet<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck1719\/large-55.jpg","html":null}]}]},"download":"https:\/\/on.notist.cloud\/pdf\/deck-591048735b17a3cc.pdf"},"relationships":{"data":[{"type":"events","id":"ev_EJSm2r","attributes":{"title":"Devops DDay","slug":"devops-dday","starts_on":"2018-11-15 08:00:00","ends_on":"2018-11-15 18:00:00","timezone":"GMT","address":"Marseille, France","latitude":"43.296482","longitude":"5.369780","country_code":"FR","url":null},"links":{"self":"https:\/\/noti.st\/events\/EJSm2r\/devops-dday","related":"https:\/\/noti.st\/events\/EJSm2r.json"}}]},"links":{"self":"https:\/\/speaker.pilato.fr\/N1EmNk\/centralized-logging-patterns"}}]}