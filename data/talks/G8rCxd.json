{"data":[{"type":"presentations","id":"pr_G8rCxd","attributes":{"title":"Randomized testing: Gotta Catch \u2018Em All","slug":"randomized-testing-gotta-catch-em-all","blurb":{"html":"<blockquote>\n<p>Chance does things well.<\/p>\n<\/blockquote>\n<p>If we apply this idea to unit tests or integration tests, we can make our tests much more unpredictable \u2014 and as a result, uncover issues that our minds would never have dared to imagine! For example, I recently discovered a <a href=\"https:\/\/github.com\/gestalt-config\/gestalt\/issues\/242\" target=\"_blank\" rel=\"noopener\">bug<\/a> in a configuration management library that occurs when the <code>Locale<\/code> is set to <code>AZ<\/code>. \ud83e\udd26\ud83c\udffc\u200d\u2642\ufe0f<\/p>\n<p>Another, even simpler, example:<\/p>\n<pre><code class=\"language-java\">int input = generateInteger(Integer.MIN_VALUE, Integer.MAX_VALUE);\nint output = Math.abs(input);\n<\/code><\/pre>\n<p>This can generate <code>-2147483648<\/code>\u2026 which is quite unexpected for an absolute value! \ud83d\ude09<br \/>\nRandomized tests can uncover these twisted edge cases\u2026 That\u2019s what the Elasticsearch team has been doing for years using the <a href=\"https:\/\/labs.carrotsearch.com\/randomizedtesting.html\" target=\"_blank\" rel=\"noopener\">RandomizedTesting<\/a> framework to test all their Java code.<\/p>\n<p>Add to that real integration tests using <a href=\"https:\/\/java.testcontainers.org\/modules\/elasticsearch\/\" target=\"_blank\" rel=\"noopener\">TestContainers<\/a>, and you\u2019ll have a complete approach to tests that <em>regularly fail<\/em>!<\/p>\n<p>After this talk, you\u2019ll never look at the <code>random()<\/code> function the same way again \u2014 and you\u2019ll discover how (bad) luck can actually help you! \ud83c\udf40<\/p>\n"},"slidedeck":{"data":[{"id":"sd_15095","type":"images","slides":[{"id":"sl_QNjjgV","type":"image","title":null,"desc":{"html":"<p>@dadoonet @pilato.fr @david\n14\/05\/2025\nI\u2019d like to cover today a framework we are using at Elastic in the Elasticsearch project. It\u2019s in Java but actually the whole concept could be applied to any other language you want. I did not check. It might exist already.<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck15095\/large-0.jpg","html":null},{"id":"sl_2hSXYu","type":"image","title":null,"desc":{"html":"<p>One day, I was working on my FSCrawler project, you know, for files! And I got an error from Github actions where I\u2019m running unit and integration tests anytime I\u2019m pushing a new change as a Pull Request.<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck15095\/large-1.jpg","html":null},{"id":"sl_f1BLRJ","type":"image","title":null,"desc":{"html":"<p>https:\/\/github.com\/dadoonet\/fscrawler\/actions\/runs\/14357866984\/job\/40251514398#step:4:296\nWith that I can ensure the stability of the code when I\u2019m changing the code base: well, it\u2019s tests after all\u2026 And I like a lot TDD: Tests Driven Development So I got this error in a unit test.<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck15095\/large-2.jpg","html":null},{"id":"sl_HKu9Ji","type":"image","title":null,"desc":{"html":"<p>Throwable #1: java.lang.NullPointerException: Cannot invoke \u201cElasticsearch.setIndex(String)\u201d because the return value of \u201cFsSettings.getElasticsearch()\u201d is null\n@Test public void settingsValidation() { FsSettings settings = FsSettingsLoader.load(); settings.getElasticsearch().setIndex(getCurrentTestName()); \/\/ \u2026 }\nThe error message is that you can not call \u201csetIndex\u201d on the Elasticsearch object here, because the Elasticsearch object actually does not exist. Although it should be loaded by FsSettingsLoader.load().<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck15095\/large-3.png","html":null},{"id":"sl_tecxC7","type":"image","title":null,"desc":{"html":"<p>@Test public void settingsValidation() { FsSettings settings = FsSettingsLoader.load(); settings.getElasticsearch().setIndex(getCurrentTestName()); \/\/ \u2026 }\nSo, as a developer, you try to run it locally from your IDE. And it does not fail. getElasticsearch() is not null. So why this is happening here? If look back at the maven failure report, here is what we can see..<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck15095\/large-4.jpg","html":null},{"id":"sl_VyLl4W","type":"image","title":null,"desc":{"html":"<p>REPRODUCE WITH: mvn integration-test -Dtests.locale=az Throwable #1: java.lang.NullPointerException: Cannot invoke \u201cElasticsearch.setIndex(String)\u201d because the return value of \u201cFsSettings.getElasticsearch()\u201d is null\nWhen you look at the maven logs you can see this message which invites you to run a given command line. And if you run this command locally, then it fails indeed\u2026<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck15095\/large-5.png","html":null},{"id":"sl_8I4Ywv","type":"image","title":null,"desc":{"html":"<p>So the Locale here is something important. We do have a specific context where it fails vs where it does not. Should we write all the possible contexts? How many Locale do we have here? More than 1 thousand. How could we test that?<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck15095\/large-6.jpg","html":null},{"id":"sl_kbnMpK","type":"image","title":null,"desc":{"html":"<p>Welcome to Randomized Testing framework. It\u2019s a framework built by Carrot Search. It\u2019s an extension for JUnit and it alters the context of the execution of the tests, like the Locale, but also the Timezone and it will provide some random methods\u2026 Like:<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck15095\/large-7.jpg","html":null},{"id":"sl_MvWAhj","type":"image","title":null,"desc":{"html":""},"image":"https:\/\/on.notist.cloud\/slides\/deck15095\/large-8.jpg","html":null},{"id":"sl_zFEya8","type":"image","title":null,"desc":{"html":"<p>So you have plenty of random. But what happens when you miss your target and your test fails? How can you reproduce the problem in the same context? You can of course log and print all the details of the Locale used, the Timezone, or whatever\u2026 How to make sure that you can run the same test locally and have the same \u201crandom\u201d values?<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck15095\/large-9.jpg","html":null},{"id":"sl_bYxmSX","type":"image","title":null,"desc":{"html":"<p>A random number is actually never a random number. It\u2019s always computed from a seed value which could be created from the timestamp for example. But if you provide a seed, the \u201crandom\u201d values computed from that seed will always be the same, when executed in the same order. So running the test again with the given seed will create the exact same context.<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck15095\/large-10.jpg","html":null},{"id":"sl_DsgaKw","type":"image","title":null,"desc":{"html":"<p>REPRODUCE WITH: mvn integration-test -Dtests.seed=489581FE40712E4A -Dtests.locale=az -Dtests.timezone=Asia\/Ashkhabad\n@Test @Seed(\u201c489581FE40712E4A\u201d) public void settingsValidationForLocaleAz() { \/\/ \u2026 }\nYou can set the seed from the CLI or if you want to always test this context, you can create a new test and annotate it with the seed value. BTW you can also notice the timezone here which is different.<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck15095\/large-11.jpg","html":null},{"id":"sl_qCPODL","type":"image","title":null,"desc":{"html":"<p>@Test @Repeat(iterations = 10) public void repeatMe() { Locale locale = randomLocale(); DateTimeFormatter dateTimeFormatter = DateTimeFormatter.ofLocalizedDate(FormatStyle.FULL).withLocale(locale); String format = dateTimeFormatter.format(LocalDate.now()); System.out.println(\u201cdate is [\u201d + format + \u201c] with locale [\u201d + locale.toLanguageTag() + \u201c]\u201d); }\nSometimes, you could repeat the same test multiple times within the same run. For that, you can use the Repeat annotation. It will run the same test 10 times but note the seed value here. It has a \u201csubseed\u201d value. Which is set from the first seed but for every new run of the same test.<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck15095\/large-12.jpg","html":null},{"id":"sl_SW8C5k","type":"image","title":null,"desc":{"html":"<p>@RunWith(RandomizedRunner.class) public class RandomTest { @Test public void stopYourThreads() { new Thread(new Runnable() { public void run() { while (true) { try { Thread.sleep(1000L); } catch (InterruptedException e) { } } } }, \u201cfriendly-zombie\u201d).start(); } }\nSome other benefits of this framework, and this might not apply to other languages than Java, is that you can also detect for non terminated threads when you close the test suite. Normally, a Thread should be closed when you exit an application.<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck15095\/large-13.png","html":null},{"id":"sl_4pqzy9","type":"image","title":null,"desc":{"html":"<p>@RunWith(RandomizedRunner.class) public class RandomTest { @Test public void stopYourThreads() { new Thread(new Runnable() { public void run() { while (true) { try { Thread.sleep(1000L); } catch (InterruptedException e) { } } } }, \u201cfriendly-zombie\u201d).start(); } } com.carrotsearch.randomizedtesting.ThreadLeakError: 1 thread leaked from SUITE scope at fr.pilato.demo.testframework.RandomTest: 1) Thread[id=12, name=Thread-1, state=TIMED_WAITING, group=TGRP-RandomTest] at java.lang.Thread.sleep(Native Method) at fr.pilato.demo.testframework.RandomTest$1.run(RandomTest.java:180) at java.lang.Thread.run(Thread.java:745) at __randomizedtesting.SeedInfo.seed([1CD01D6C55CD93C0]:0)\nHere, it\u2019s detected that you did not close the thread. And indeed, we just started a thread and never closed it explicitly so the JVM will keep it running forever until the JVM closes.<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck15095\/large-14.jpg","html":null},{"id":"sl_h9ZnqY","type":"image","title":null,"desc":{"html":"<p>@RunWith(RandomizedRunner.class) @ThreadLeakFilters(filters = { FriendlyZombieFilter.class }) public class RandomTest extends RandomizedTest { @Test public void identifyYourThreads() { new Thread(new Runnable() { public void run() { while (true) { try { Thread.sleep(1000L); } catch (InterruptedException e) { } } } }, \u201cfriendly-zombie\u201d).start(); } } public class FriendlyZombieFilter implements ThreadFilter { public boolean reject(Thread t) { if (\u201cfriendly-zombie\u201d.equals(t.getName())) { return true; } return false; } }\nBut sometimes you don\u2019t have access to the code which is running. For example when you use a 3rd party library which is not coded the right way. May be you want to ignore that specific thread. The example shown here adds a filter which ignores a remaining thread named \u201cfriendly-zombie\u201d.<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck15095\/large-15.jpg","html":null},{"id":"sl_JTIbix","type":"image","title":null,"desc":{"html":"<p>https:\/\/github.com\/gestalt-config\/gestalt\/issues\/242\nWhat happened to the failing test? I created a full reproduction script, outside the context of FSCrawler, without RandomizedTesting but just with the Locale set to AZ. The second test passes when using FR as a Locale but not the first one with AZ.<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck15095\/large-16.jpg","html":null},{"id":"sl_vn1PbM","type":"image","title":null,"desc":{"html":"<p>https:\/\/github.com\/gestalt-config\/gestalt\/issues\/242\nIt happened to be a problem when they are running a regular expression\u2026 They did not set the Locale properly which had some side effects here. After the PR was merged, I was able to confirm the behavior by running the test with the initial seed again. And it passed.<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck15095\/large-17.jpg","html":null},{"id":"sl_Y6kDTl","type":"image","title":null,"desc":{"html":"<p>So let the tests run continuously with different contexts (different seeds) like a Roomba vacuum cleaner would do and let it catch all the errors for you.<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck15095\/large-18.jpg","html":null},{"id":"sl_AQT1MA","type":"image","title":null,"desc":{"html":"<p>So having your CI failing frequently is good and what you would like to happen. That means that after thousand of runs or more, you might have tested a lot of your code base.<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck15095\/large-19.jpg","html":null}]}]},"download":"https:\/\/on.notist.cloud\/pdf\/deck-d1dc54fcfb7ede16.pdf"},"relationships":{"data":[{"type":"events","id":"ev_MQurda","attributes":{"title":"Elastic EAH (private event)","slug":"elastic-eah-private-event","starts_on":"2025-05-13 08:00:00","ends_on":"2025-05-15 18:00:00","timezone":"America\/Los_Angeles","address":"Las Vegas, NV, USA","latitude":"36.169941","longitude":"-115.139830","country_code":"US","url":null},"links":{"self":"https:\/\/noti.st\/events\/MQurda\/elastic-eah-private-event","related":"https:\/\/noti.st\/events\/MQurda.json"}}]},"links":{"self":"https:\/\/speaker.pilato.fr\/G8rCxd\/randomized-testing-gotta-catch-em-all"}}]}