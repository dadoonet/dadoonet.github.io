{"data":[{"type":"presentations","id":"pr_lYu3b1","attributes":{"title":"Les Vendredis noirs : m\u00eame pas peur !","slug":"les-vendredis-noirs-meme-pas-peur","blurb":{"html":"<p>Surveiller une application complexe n\u2019est pas une t\u00e2che ais\u00e9e, mais avec les bons outils, ce n\u2019est pas si sorcier. N\u00e9anmoins, des p\u00e9riodes fortes telles que les op\u00e9rations de type \u201cBlack Friday\u201d (Vendredi noir) ou p\u00e9riode de No\u00ebl peuvent pousser votre application aux limites de ce qu\u2019elle peut supporter, ou pire, la faire crasher. Parce que le syst\u00e8me est fortement sollicit\u00e9, il g\u00e9n\u00e8re encore davantage de logs qui peuvent \u00e9galement mettre \u00e0 mal votre syst\u00e8me de supervision.<\/p>\n<p>Dans cette session, j\u2019aborderai les bonnes pratiques d\u2019utilisation de la suite Elastic pour centraliser et monitorer vos logs. Je partagerai \u00e9galement avec vous quelques trucs et astuces pour vous aider \u00e0 passer sans souci vos Vendredis noirs !<\/p>\n"},"slidedeck":{"data":[{"id":"sd_2284","type":"images","slides":[{"id":"sl_RbqPzG","type":"image","title":null,"desc":{"html":"<p>Les vendredi noirs ? M\u00eame pas peur !\nDavid Pilato Developer | Evangelist, @dadoonet<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck2284\/large-0.jpg","html":null},{"id":"sl_3vZDrf","type":"image","title":null,"desc":{"html":"<p>Data Platform Architectures<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck2284\/large-1.jpg","html":null},{"id":"sl_gFI1k4","type":"image","title":null,"desc":{"html":"<p>The Elastic Journey of Data Beats\nLog Files\nWire Data\nMetrics your{beat}\n!3\n@dadoonet\nsli.do\/elastic<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck2284\/large-2.jpg","html":null},{"id":"sl_IZ0pcT","type":"image","title":null,"desc":{"html":"<p>The Elastic Journey of Data Beats\nLog Files\nElasticsearch\nMaster Nodes (3)\nWire Data\nIngest Nodes (X) Metrics your{beat}\nData Nodes Hot (X) Data Notes Warm (X)\n!4\n@dadoonet\nsli.do\/elastic<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck2284\/large-3.jpg","html":null},{"id":"sl_usjdUs","type":"image","title":null,"desc":{"html":"<p>The Elastic Journey of Data Beats\nLog Files\nElasticsearch\nMaster Nodes (3)\nWire Data\nIngest Nodes (X) Metrics your{beat}\nData Nodes Hot (X) Data Notes Warm (X)\n!5\n@dadoonet\nsli.do\/elastic\nKibana\nInstances (X)<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck2284\/large-4.jpg","html":null},{"id":"sl_XCSRNH","type":"image","title":null,"desc":{"html":"<p>The Elastic Journey of Data Beats\nElasticsearch Logstash\nLog Files\nWire Data\nMaster Nodes (3) Ingest Nodes (X)\nMetrics your{beat}\nNodes (X)\nData Nodes Hot (X) Data Notes Warm (X)\n!6\n@dadoonet\nsli.do\/elastic\nKibana\nInstances (X)<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck2284\/large-5.jpg","html":null},{"id":"sl_9WBFFg","type":"image","title":null,"desc":{"html":"<p>The Elastic Journey of Data Beats\nElasticsearch Logstash\nLog Files\nWire Data\nMaster Nodes (3) Ingest Nodes (X)\nMetrics your{beat}\n!7\nData Store\nWeb APIs\nSocial\nSensors\nNodes (X)\nData Nodes Hot (X) Data Notes Warm (X)\n@dadoonet\nsli.do\/elastic\nKibana\nInstances (X)<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck2284\/large-6.jpg","html":null},{"id":"sl_lpu385","type":"image","title":null,"desc":{"html":"<p>The Elastic Journey of Data Beats\nElasticsearch Logstash\nLog Files\nWire Data\nMaster Nodes (3)\nKibana\nIngest Nodes (X) Metrics your{beat}\nData Store\nWeb APIs\nSocial\nSensors\nNodes (X)\nData Nodes Hot (X) Data Notes Warm (X)\nQueues\n!8\nInstances (X)\n@dadoonet\nStorage\nMetrics Notification\nsli.do\/elastic<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck2284\/large-7.jpg","html":null},{"id":"sl_O9cr0U","type":"image","title":null,"desc":{"html":"<p>The Elastic Journey of Data Beats\nElasticsearch Logstash\nLog Files\nWire Data\nMaster Nodes (3)\nKibana\nIngest Nodes (X) Metrics your{beat}\nKafka\nNodes (X) Redis\nMessaging Queue\nData Store\nWeb APIs\nSocial\nSensors\nData Nodes Hot (X) Data Notes Warm (X)\nQueues\n!9\nInstances (X)\n@dadoonet\nStorage\nMetrics Notification\nsli.do\/elastic<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck2284\/large-8.jpg","html":null},{"id":"sl_0TLest","type":"image","title":null,"desc":{"html":"<p>App Search\nSite Search\nEnterprise Search\nLogging\nAPM\nBusiness Analytics\nSecurity Analytics\nMetrics\nElastic Stack\nFuture\nSolutions\nKibana\nVisualize &amp; Manage\nElasticsearch\nStore, Search, &amp; Analyze\nBeats\nSaaS\nElastic Cloud\nLogstash\nIngest\nSelf Managed\nStandalone\nElastic Cloud Enterprise\nDeployment<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck2284\/large-9.png","html":null},{"id":"sl_cn4SlI","type":"image","title":null,"desc":{"html":"<p>Elasticsearch Cluster Sizing<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck2284\/large-10.png","html":null},{"id":"sl_F6nGdh","type":"image","title":null,"desc":{"html":"<p>Terminology Cluster my_cluster Server 1 Node A d1 d3\nd6 d2\nd4 d9 d12\nd11 d7 d8\nd5\nd3 d1\nd10\nd4\nIndex twitter\nd6 d2 d5\nIndex logs\n!12\n@dadoonet\nsli.do\/elastic<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck2284\/large-11.jpg","html":null},{"id":"sl_rQW4W6","type":"image","title":null,"desc":{"html":"<p>Partition Cluster my_cluster Server 1 d1\n4\nd3\n3\nNode A\nd2 d4 d9 d12\n2\nShards\nd6 d11 d7 d8\nd5 d10\n0\n1\n1\nd3\nd1 d4\nIndex twitter\nd6 d2 d5\n0\nIndex logs\n!13\n@dadoonet\nsli.do\/elastic<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck2284\/large-12.jpg","html":null},{"id":"sl_TkEsOV","type":"image","title":null,"desc":{"html":"<p>Distribution Cluster my_cluster Server 1\nServer 2 twitter shard P4\nd1 d6\nNode B\nNode A\ntwitter shard P1\nd2 d5\nd3\nd10\nd11\ntwitter shard P0\nd7 d8\nd4 d9\ntwitter shard P3 d12\ntwitter shard P2\n!14\nd3 d1\n@dadoonet\nd6\nlogs shard P0\nd2\nd4\nd5\nlogs shard P1\nsli.do\/elastic<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck2284\/large-13.jpg","html":null},{"id":"sl_63xgGu","type":"image","title":null,"desc":{"html":"<p>Replication \u2022 Primaries \u2022 Replicas Cluster my_cluster Server 1\nServer 2 twitter shard P4\nNode B\nd1 d6 d2\nd11 d7\nd3\ntwitter shard R3 d9\nd12\ntwitter shard P2\n!15\ntwitter shard P1\nd5\nd2\nd2 d11\nd5 d1\n@dadoonet\nd6\nd8\nd9\nlogs shard R0\ntwitter shard P3\nlogs shard P0\ntwitter shard R2\ntwitter shard P0\nd7\nd6\nd2\nd4\nd5 d10\nd3\nd1\ntwitter shard R1\nd12 d3\nNode A\nd4\ntwitter shard R0 logs shard R1 d4\nd6\nd3\nd10\nd8\nd4\ntwitter shard R4\nd1\nd5\nlogs shard P1\nsli.do\/elastic<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck2284\/large-14.jpg","html":null},{"id":"sl_iNgU9J","type":"image","title":null,"desc":{"html":"<p>Replication\nServer 3 twitter shard R4\nd1 d6\nServer 2\nNode C\ntwitter shard P4\ntwitter shard P1\nd2\nd10\ntwitter shard R3 d9\ntwitter shard P2\n!16\nd6\nNode A\nd2\nd8\nd4\nd2\nd3 d1\nlogs shard P1\n@dadoonet\nlogs shard R0\ntwitter shard P3\ntwitter shard R1\nd12\nd5 d5\nd8\nd9\nd2 d6\nlogs shard P0\ntwitter shard R2\nsli.do\/elastic\ntwitter shard P0\nd7\nd4\ntwitter shard R0 logs shard R1 d4\nd11\nd3\nd7\nd3\nd4\nNode B\nd1\nd11\nd5\nd12\n\u2022 Primaries \u2022 Replicas Cluster my_cluster Server 1\nd5 d10\nd1\nd3\nd6<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck2284\/large-15.jpg","html":null},{"id":"sl_KhPI1i","type":"image","title":null,"desc":{"html":"<p>Scaling Data\n!17\n@dadoonet\nsli.do\/elastic<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck2284\/large-16.jpg","html":null},{"id":"sl_x185u7","type":"image","title":null,"desc":{"html":"<p>Scaling Data\n!18\n@dadoonet\nsli.do\/elastic<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck2284\/large-17.jpg","html":null},{"id":"sl_ZKqtmW","type":"image","title":null,"desc":{"html":"<p>Scaling Data\n!19\n@dadoonet\nsli.do\/elastic<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck2284\/large-18.jpg","html":null},{"id":"sl_BeZhev","type":"image","title":null,"desc":{"html":"<p>Scaling Big Data\n\u2026\n!20\n@dadoonet\n\u2026\nsli.do\/elastic<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck2284\/large-19.png","html":null},{"id":"sl_nyIVXK","type":"image","title":null,"desc":{"html":"<p>Scaling Big Data\n\u2026\n\u2026\n\u2022 In Elasticsearch, shards are the working unit \u2022 More data -&gt; More shards\nBut how many shards? !21\n@dadoonet\nsli.do\/elastic<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck2284\/large-20.png","html":null},{"id":"sl_QI1JPj","type":"image","title":null,"desc":{"html":"<p>How much data?\n\u2022 ~1000 events per second \u2022 60s * 60m * 24h * 1000 events =&gt; ~87M events per day \u2022 1kb per event =&gt; ~82GB per day \u2022 3 months =&gt; ~7TB\n!22\n@dadoonet\nsli.do\/elastic<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck2284\/large-21.jpg","html":null},{"id":"sl_2bk7I8","type":"image","title":null,"desc":{"html":"<p>Shard Size \u2022 It depends on many different factors \u2012 document size, mapping, use case, kinds of queries being executed, desired response time, peak indexing rate, budget, \u2026 \u2022 After the shard sizing*, each shard should handle 45GB \u2022 Up to 10 shards per machine<\/p>\n<ul>\n<li>https:\/\/www.elastic.co\/elasticon\/conf\/2016\/sf\/quantitative-cluster-sizing !23\n@dadoonet\nsli.do\/elastic<\/li>\n<\/ul>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck2284\/large-22.jpg","html":null},{"id":"sl_evSvAX","type":"image","title":null,"desc":{"html":"<p>How many shards?\n\u2022 Data size: ~7TB\n\u2022\nShards per machine: 10*\n\u2022 Shard Size: ~45GB*\n\u2022\nTotal Servers: 16\n\u2022 Total Shards: ~160 3 months of logs Cluster my_cluster\n\u2026 * https:\/\/www.elastic.co\/elasticon\/conf\/2016\/sf\/quantitative-cluster-sizing !24\n@dadoonet\nsli.do\/elastic<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck2284\/large-23.png","html":null},{"id":"sl_HFBj2w","type":"image","title":null,"desc":{"html":"<p>But\u2026\n\u2022 How many indices? \u2022 What do you do if the daily data grows? \u2022 What do you do if you want to delete old data?\n!25\n@dadoonet\nsli.do\/elastic<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck2284\/large-24.jpg","html":null},{"id":"sl_tYuWvL","type":"image","title":null,"desc":{"html":"<p>Time-Based Data\n\u2022 Logs, social media streams, time-based events \u2022 Timestamp + Data \u2022 Do not change \u2022 Typically search for recent events \u2022 Older documents become less important \u2022 Hard to predict the data size\n!26\n@dadoonet\nsli.do\/elastic<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck2284\/large-25.png","html":null},{"id":"sl_VsdKnk","type":"image","title":null,"desc":{"html":"<p>Time-Based Data\n\u2022 Time-based Indices is the best option \u2012 create a new index each day, week, month, year, \u2026 \u2012 search the indices you need in the same request\n!27\n@dadoonet\nsli.do\/elastic<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck2284\/large-26.png","html":null},{"id":"sl_8CM8g9","type":"image","title":null,"desc":{"html":"<p>Daily Indices Cluster my_cluster d3 d1 d4\nd6 d2 d5\nlogs-2018-04-10\n!28\n@dadoonet\nsli.do\/elastic<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck2284\/large-27.jpg","html":null},{"id":"sl_kW4wYY","type":"image","title":null,"desc":{"html":"<p>Daily Indices Cluster my_cluster d3 d1 d4\nd6 d2 d5\nlogs-2018-04-10 d3 d1 d4\nd6 d2 d5\nlogs-2018-04-11\n!29\n@dadoonet\nsli.do\/elastic<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck2284\/large-28.jpg","html":null},{"id":"sl_MpnkQx","type":"image","title":null,"desc":{"html":"<p>Daily Indices Cluster my_cluster d3 d1 d4\nd6 d2 d5\nlogs-2018-04-10 d3 d1 d4\nd6 d2 d5\nlogs-2018-04-11 d3 d1 d4\nd6 d2 d5\nlogs-2018-04-12 !30\n@dadoonet\nsli.do\/elastic<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck2284\/large-29.jpg","html":null},{"id":"sl_z9WYJM","type":"image","title":null,"desc":{"html":"<p>Templates\n\u2022 Every new created index starting with \u2018logs-\u2019 will have \u2012 2 shards \u2012 1 replica (for each primary shard) \u2012 60 seconds refresh interval PUT _template\/logs { \u201ctemplate\u201d: \u201clogs-*\u201d, \u201csettings\u201d: { \u201cnumber_of_shards\u201d: 2, \u201cnumber_of_replicas\u201d: 1, \u201crefresh_interval\u201d: \u201c60s\u201d } }\nMore on that later !31\n@dadoonet<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck2284\/large-30.png","html":null},{"id":"sl_bTFMBl","type":"image","title":null,"desc":{"html":"<p>Alias Cluster my_cluster d3 d1 d4\nlogs-write\nlogs-2018-04-10\nusers\n@dadoonet\nd2 d5\nlogs-read Application\n!32\nd6\nsli.do\/elastic<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck2284\/large-31.jpg","html":null},{"id":"sl_DmyA4A","type":"image","title":null,"desc":{"html":"<p>Alias Cluster my_cluster d3 d1 d4\nlogs-write\nd2 d5\nlogs-2018-04-10 d3\nlogs-read Application\nd6\nd1 d4\nd6 d2 d5\nlogs-2018-04-11\nusers\n!33\n@dadoonet\nsli.do\/elastic<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck2284\/large-32.jpg","html":null},{"id":"sl_q6gxwZ","type":"image","title":null,"desc":{"html":"<p>Alias Cluster my_cluster d3 d1 d4\nlogs-write\nd2 d5\nlogs-2018-04-10 d3\nlogs-read Application\nd6\nd1 d4\nd6 d2 d5\nlogs-2018-04-11 d3\nusers\nd1 d4\nd6 d2 d5\nlogs-2018-04-12 !34\n@dadoonet\nsli.do\/elastic<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck2284\/large-33.jpg","html":null},{"id":"sl_SQPloy","type":"image","title":null,"desc":{"html":"<p>Detour: Rollover API\nhttps:\/\/www.elastic.co\/guide\/en\/elasticsearch\/reference\/6.3\/indices-rollover-index.html<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck2284\/large-34.jpg","html":null},{"id":"sl_4k8ZhN","type":"image","title":null,"desc":{"html":"<p>Do not Overshard don\u2019t keep default values!\nCluster my_cluster d3\nd6\nd1\n\u2022 3 different logs\nd2\nd4\nd5\n\u2022 1 index per day each\naccess-\u2026\n\u2022 1GB each\nd5\n\u2022 5 shards (default): so 200mb \/ shard vs 45gb\nd1 d7\nd6 d9 d5\n\u2022 6 months retention\napplication-\u2026\n\u2022 ~900 shards for ~180GB\nd59\n\u2022 we needed ~4 shards!\nd0 d4\nd10 d3 d5\nmysql-\u2026 !36\n@dadoonet\nsli.do\/elastic<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck2284\/large-35.jpg","html":null},{"id":"sl_h3rNZm","type":"image","title":null,"desc":{"html":"<p>Scaling Big Data 1M users\n\u2026\n\u2026\nBut what happens if we have 2M users?\n!37\n@dadoonet\nsli.do\/elastic<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck2284\/large-36.png","html":null},{"id":"sl_JNaBSB","type":"image","title":null,"desc":{"html":"<p>Scaling Big Data\n!38\n1M users\n\u2026\n\u2026\n1M users\n\u2026\n\u2026\n@dadoonet\nsli.do\/elastic<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck2284\/large-37.png","html":null},{"id":"sl_vhIzKa","type":"image","title":null,"desc":{"html":"<p>Scaling Big Data\n!39\n1M users\n\u2026\n\u2026\n1M users\n\u2026\n\u2026\n1M users\n\u2026\n\u2026\n@dadoonet\nsli.do\/elastic<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck2284\/large-38.png","html":null},{"id":"sl_Y11nCz","type":"image","title":null,"desc":{"html":"<p>Scaling Big Data\nU s e r s\n!40\n\u2026\n\u2026\n\u2026\n\u2026\n\u2026\n\u2026\n@dadoonet\nsli.do\/elastic<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck2284\/large-39.png","html":null},{"id":"sl_AKkb5O","type":"image","title":null,"desc":{"html":"<p>Shards are the working unit\n\u2022 Primaries \u2012 More data -&gt; More shards \u2012 write throughput (More writes -&gt; More primary shards) \u2022 Replicas \u2012 high availability (1 replica is the default) \u2012 read throughput (More reads -&gt; More replicas)\n!41\n@dadoonet\nsli.do\/elastic<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck2284\/large-40.png","html":null},{"id":"sl_meTOxn","type":"image","title":null,"desc":{"html":"<p>Detour: Shrink API\nhttps:\/\/www.elastic.co\/guide\/en\/elasticsearch\/reference\/6.3\/indices-shrink-index.html<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck2284\/large-41.jpg","html":null},{"id":"sl_OyCCqC","type":"image","title":null,"desc":{"html":"<p>Detour: Split API\nhttps:\/\/www.elastic.co\/guide\/en\/elasticsearch\/reference\/6.3\/indices-split-index.html<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck2284\/large-42.jpg","html":null},{"id":"sl_1Hv0ib","type":"image","title":null,"desc":{"html":"<p>Optimal Bulk Size<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck2284\/large-43.jpg","html":null},{"id":"sl_dbdob0","type":"image","title":null,"desc":{"html":"<p>What is Bulk? 1000 index requests with 1 document __________ __________ __________ __________ __________ __________ __________ __________ __________ __________ __________ __________ __________ __________ __________ __________ __________ __________ __________ __________ __________ __________ __________ __________ __________ __________ __________ __________ __________ __________ __________ __________ __________ __________ __________ __________ __________ __________ __________ __________ _____\nMaster Nodes (3) Ingest Nodes (X)\nBeats Logstash Application\nData Nodes Hot (X)\n1000 log events\n1 bulk request with 1000 documents\n!45\nElasticsearch\n@dadoonet\nsli.do\/elastic\nData Notes Warm (X)<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck2284\/large-44.jpg","html":null},{"id":"sl_FvMcTP","type":"image","title":null,"desc":{"html":"<p>What is the optimal bulk size? Elasticsearch<\/p>\n<hr \/>\n<p>Beats Logstash Application\n1000 log events\n!46\n@dadoonet\n4 * 250? 2 * 500? 1 * 1000?\nMaster Nodes (3) Ingest Nodes (X) Data Nodes Hot (X) Data Notes Warm (X)\nsli.do\/elastic<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck2284\/large-45.jpg","html":null},{"id":"sl_sF5QLo","type":"image","title":null,"desc":{"html":"<p>It depends\u2026\n\u2022 on your application (language, libraries, \u2026) \u2022 document size (100b, 1kb, 100kb, 1mb, \u2026) \u2022 number of nodes \u2022 node size \u2022 number of shards \u2022 shards distribution\n!47\n@dadoonet\nsli.do\/elastic<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck2284\/large-46.jpg","html":null},{"id":"sl_UYoEED","type":"image","title":null,"desc":{"html":"<p>Test it ;) Elasticsearch<\/p>\n<hr \/>\n<p>1000000 log events\n4000 * Beats Logstash Application\n2000 *\n250-&gt; 160s\nMaster Nodes (3)\n500-&gt; 164s\nIngest Nodes (X)\n1000 * 1000-&gt; 155s\nData Nodes Hot (X) Data Notes Warm (X)\n!48\n@dadoonet\nsli.do\/elastic<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck2284\/large-47.jpg","html":null},{"id":"sl_6sX26c","type":"image","title":null,"desc":{"html":"<p>Test it ;) input { stdin{} } filter {} output { elasticsearch { hosts =&gt; [\u201c10.12.145.189\u201d] flush_size =&gt; \u201c${SIZE}\u201d } }\nIn Beats set \u201cbulk_max_size\u201d in the output.elasticsearch\nDATE=<code>date +%Y.%m.%d<\/code> LOG=logs\/logs.txt exec_test () { curl -s -XDELETE \u201chttp:\/\/USER:PASS@HOST:9200\/logstash-$DATE\u201d sleep 10 export SIZE=$1 time cat $LOG | .\/bin\/logstash -f logstash.conf } for SIZE in 100 500 1000 3000 5000 10000; do for i in {1..20}; do exec_test $SIZE done; done; !49\n@dadoonet\nsli.do\/elastic<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck2284\/large-48.png","html":null},{"id":"sl_jCFpz1","type":"image","title":null,"desc":{"html":"<p>Test it ;)\n\u2022 2 node cluster (m3.large) \u2012 2 vCPU, 7.5GB Memory, 1x32GB SSD \u2022 1 index server (m3.large) \u2012 logstash \u2012 kibana\n!50<\/p>\n<h1>docs<\/h1>\n<p>100\n500\n1000\n3000\n5000\n10000\ntime(s)\n191.7\n161.9\n163.5\n160.7\n160.7\n161.5\n@dadoonet<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck2284\/large-49.png","html":null},{"id":"sl_LVydrQ","type":"image","title":null,"desc":{"html":"<p>Distribute the Load<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck2284\/large-50.jpg","html":null},{"id":"sl_xphRjp","type":"image","title":null,"desc":{"html":"<p>Avoid Bottlenecks Elasticsearch\nsingle node _________ _________ _________ _________ _________ _________ _________ _________ _________ _________ _________ _________ _________ _________ _________ _________ _________ _________ _________ _________ _________ _________ _________ _________ _________ _________ _________ _________ _________ _________ _________ _________ _________ _________ _________\nNode 1 Beats Logstash Application\n1000000 log events\nround robin\nNode 2\noutput { elasticsearch { hosts =&gt; [\u201cnode1\u201d,\u201dnode2\u201d] } }\n!52\n@dadoonet\nsli.do\/elastic<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck2284\/large-51.jpg","html":null},{"id":"sl_a9QFcE","type":"image","title":null,"desc":{"html":"<p>Load Balancer Elasticsearch<\/p>\n<hr \/>\n<p>Node 1 Beats Logstash\nLB\nApplication\nNode 2\n1000000 log events\n!53\n@dadoonet\nsli.do\/elastic<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck2284\/large-52.jpg","html":null},{"id":"sl_CT93Ud","type":"image","title":null,"desc":{"html":"<p>Coordinating-only Node Elasticsearch<\/p>\n<hr \/>\n<p>Node 1 Beats Logstash\nNode 3 co-node\nApplication\nNode 2\n1000000 log events\n!54\n@dadoonet\nsli.do\/elastic<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck2284\/large-53.jpg","html":null},{"id":"sl_omrrN2","type":"image","title":null,"desc":{"html":"<p>Test it ;) \u2022 2 node cluster (m3.large) \u2012 2 vCPU, 7.5GB Memory, 1x32GB SSD \u2022 1 index server (m3.large) \u2012 logstash (round robin configured) \u2012\nhosts =&gt; [\u201c10.12.145.189\u201d, \u201c10.121.140.167\u201d]\n\u2012 kibana\n!55\n#docs time(s)\n1000\n5000\n10000\nNO Round Robin\n163.5\n160.7\n161.5\nRound Robin\n161.3\n158.2\n159.4\n@dadoonet\nsli.do\/elastic<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck2284\/large-54.png","html":null},{"id":"sl_R6afFR","type":"image","title":null,"desc":{"html":"<p>Optimizing Disk IO<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck2284\/large-55.jpg","html":null},{"id":"sl_3QJT7q","type":"image","title":null,"desc":{"html":"<p>Durability time buffer index a doc\nbuffer index a doc\nbuffer index a doc\nbuffer\n!57\n@dadoonet\nlucene flush\nsegment<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck2284\/large-56.png","html":null},{"id":"sl_fk2H0F","type":"image","title":null,"desc":{"html":"<p>refresh_interval\n\u2022 Dynamic per-index setting PUT logstash-2017.05.16\/_settings { \u201crefresh_interval\u201d: \u201c60s\u201d }\n\u2022 Increase to get better write throughput to an index \u2022 New documents will take more time to be available for Search.\n!58\n#docs time(s)\n1000\n5000\n10000\n1s refresh 60s refresh\n161.3 156.7\n158.2 152.1\n159.4 152.6\n@dadoonet<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck2284\/large-57.png","html":null},{"id":"sl_I3l4se","type":"image","title":null,"desc":{"html":"<p>Durability time\nbuffer index a doc\ndoc op\ntrans_log buffer\nlucene flush\nsegment\ntrans_log buffer elasticsearch flush\nlucene commit\ntrans_log\n!59\n@dadoonet\nsegment segment<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck2284\/large-58.png","html":null},{"id":"sl_uNTsl3","type":"image","title":null,"desc":{"html":"<p>Translog fsync every 5s (1.7) buffer\nPrimary\nindex a doc\ndoc op\ntrans_log buffer\nReplica\nindex a doc\ndoc op\ntrans_log\nredundancy doesn\u2019t help if all nodes lose power !60\n@dadoonet<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck2284\/large-59.jpg","html":null},{"id":"sl_WhCgdS","type":"image","title":null,"desc":{"html":"<p>Translog fsync on every request \u2022 For low volume indexing, fsync matters less \u2022 For high volume indexing, we can amortize the costs and fsync on every bulk \u2022 Concurrent requests can share an fsync bulk 1\nsingle fsync\nbulk 2\n!61\n@dadoonet\nsli.do\/elastic<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck2284\/large-60.jpg","html":null},{"id":"sl_90vUVr","type":"image","title":null,"desc":{"html":"<p>Async Transaction Log \u2022 index.translog.durability \u2012 request (default) \u2012 async \u2022 index.translog.sync_interval (only if async is set) \u2022 Dynamic per-index settings \u2022 Be careful, you are relaxing the safety guarantees\n!62\n#docs time(s)\n1000\n5000\n10000\nRequest fsync\n161.3\n158.2\n159.4\n5s sync\n152.4\n149.1\n150.3\n@dadoonet<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck2284\/large-61.png","html":null},{"id":"sl_lKeIOG","type":"image","title":null,"desc":{"html":"<p>Final Remarks<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck2284\/large-62.jpg","html":null},{"id":"sl_NeN6Gf","type":"image","title":null,"desc":{"html":"<p>App Search\nSite Search\nEnterprise Search\nLogging\nAPM\nBusiness Analytics\nSecurity Analytics\nMetrics\nElastic Stack\nFuture\nSolutions\nKibana\nVisualize &amp; Manage\nElasticsearch\nStore, Search, &amp; Analyze\nBeats\nSaaS\nElastic Cloud\nLogstash\nIngest\nSelf Managed\nStandalone\nElastic Cloud Enterprise\nDeployment<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck2284\/large-63.png","html":null},{"id":"sl_zy5u94","type":"image","title":null,"desc":{"html":"<p>Final Remarks \u2022 Primaries \u2012 More data -&gt; More shards \u2012 Do not overshard! \u2022 Replicas \u2012 high availability (1 replica is the default) \u2012 read throughput (More reads -&gt; More replicas) Big Data\nU s e r s\n!65\n@dadoonet\n\u2026\n\u2026\n\u2026\n\u2026\n\u2026\n\u2026\nsli.do\/elastic<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck2284\/large-64.png","html":null},{"id":"sl_cHoi1T","type":"image","title":null,"desc":{"html":"<p>Final Remarks \u2022 Bulk and Test \u2022 Distribute the Load \u2022 Refresh Interval \u2022 Async Trans Log (careful)\n!66\n#docs per bulk\n1000\n5000\n10000\nDefault\n163.5\n160.7\n161.5\nRR+60s+Async5s\n152.4\n149.1\n150.3\n@dadoonet<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck2284\/large-65.png","html":null},{"id":"sl_EbXVts","type":"image","title":null,"desc":{"html":"<p>Les vendredi noirs ? M\u00eame pas peur !\nDavid Pilato Developer | Evangelist, @dadoonet<\/p>\n"},"image":"https:\/\/on.notist.cloud\/slides\/deck2284\/large-66.jpg","html":null}]}]},"download":null,"resources":{"data":[{"title":"Quantitative Cluster Sizing","url":"https:\/\/www.elastic.co\/fr\/elasticon\/conf\/2016\/sf\/quantitative-cluster-sizing","desc":{"html":"<p>How many shards should I have? How many nodes should I have? What about replicas? Do these questions sound familiar? The answer is often \u2018it depends\u2019. This talk will outline the factors that affect sizing and walk you through a quantitative approach to estimating the configuration and size of your cluster.<\/p>\n"}},{"title":"Rollover API","url":"https:\/\/www.elastic.co\/guide\/en\/elasticsearch\/reference\/6.6\/indices-rollover-index.html","desc":{"html":"<p>The rollover index API rolls an alias over to a new index when the existing index is considered to be too large or too old.<\/p>\n"}},{"title":"Shrink Index API","url":"https:\/\/www.elastic.co\/guide\/en\/elasticsearch\/reference\/6.6\/indices-shrink-index.html","desc":{"html":"<p>The shrink index API allows you to shrink an existing index into a new index with fewer primary shards.<\/p>\n"}},{"title":"Split Index API","url":"https:\/\/www.elastic.co\/guide\/en\/elasticsearch\/reference\/6.6\/indices-split-index.html","desc":{"html":"<p>The split index API allows you to split an existing index into a new index, where each original primary shard is split into two or more primary shards in the new index.<\/p>\n"}},{"title":"Talk video from a past session","url":"https:\/\/www.youtube.com\/watch?v=h7R79ypXJsI","desc":{"html":"<p>Talk give at DevopsDDay Marseille, November 2018.<\/p>\n"}},{"title":"Official photos from DevopsDays Geneva","url":"https:\/\/photos.app.goo.gl\/Y4yUQbPbCrdG9DpNA","desc":{"html":""}}]}},"relationships":{"data":[{"type":"events","id":"ev_wSYUDB","attributes":{"title":"Devopsdays Geneva 2019","slug":"devopsdays-geneva-2019","starts_on":"2019-02-21 08:00:00","ends_on":"2019-02-22 18:00:00","timezone":"Europe\/Zurich","address":"Geneva, Switzerland","latitude":"46.204391","longitude":"6.143158","country_code":"CH","url":null},"links":{"self":"https:\/\/noti.st\/events\/wSYUDB\/devopsdays-geneva-2019","related":"https:\/\/noti.st\/events\/wSYUDB.json"}}]},"links":{"self":"https:\/\/speaker.pilato.fr\/lYu3b1\/les-vendredis-noirs-meme-pas-peur"}}]}